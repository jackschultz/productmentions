c
image_url
n
product_group_string
n
quit
item.image_sets.image_set.first["MediumImage"]["URL"]
item.image_sets.image_set.first["SwatchImage"]["URL"]
item.image_sets.image_set.first["SwatchImage"]
item.image_sets.image_set.first
item.image_sets.image_set.swatch_image
item.image_sets.image_set
item.image_sets
item.image_set
item.item_attributes
item
c
subsite.comments
n
subsite
quit
c
ptext.css("p").xpath("text()").to_s.squish
ptext.xpath("text()").to_s
ptext.xpath("text()").to_s.squish
ptext
c
DateTime.strptime("Mon Dec 5 17:19:40 2016 UTC", "%a %b %e %k:%M:%S %Y")
DateTime.httpdate("Mon Dec 5 17:19:40 2016 UTC")
DateTime.strptime("Mon Dec 5 17:19:40 2016 UTC", "")
DateTime.strptime("Mon Dec 5 17:19:40 2016 UTC")
DateTime
comment.css("time").first["title"]
comment.css("time")["title"]
comment.css("time")
c
comment.css("li.first a").first["href"]
comment.css("li.first a").first.text
comment.css("li.first a").first.href
comment.css("li.first a").first["value"]
comment.css("li.first a").first["herf"]
comment.css("li.first a").first
comment.css("li.first a")
c
result.css("div.thing.comment").length
result.css("div.thing.comment")
result.css("div.thing.div.comment")
result
result.css("div.thing div.comment")
result.css("div.thing comment")
result.css("div[@class=comment]")
result.css("div[class=comment]")
result.css("div[class='comment']")
result.css("div[class='thing comment']")
c
result.css("div.usertext-body")
result.css("div[@class='usertext-body']")
result.css("div[class='usertext-body']")
result.css("div[class=usertext-body]")
result
result.css("div[class=usertext-body]")
comments
quit
c
comment.css("span").xpath("text()").to_s.squish
comment.css("span").xpath("text()").to_s.replace("\t\n",'')
comment.css("span").xpath("text()").to_s.gsub("\n",'')
comment.css("span").xpath("text()").to_s.gsub("\t\n",'')
comment.css("span").xpath("text()").to_s.strip()
comment.css("span").xpath("text()").to_s.strip("\t\n")
comment.css("span").xpath("text()").to_s
c
comment.css("span").xpath("text()").to_s
c
comment.css("span").xpath("text()").to_s
comment
comment.xpath("text()").to_s
c
comment.xpath("text()").to_s
c
comment.xpath("text()").to_s
c
comment.xpath("text()").to_s
c
comment.xpath("text()").to_s
comment.to_s
comment.xpath("//text()").to_s
comment
comments
comment.css("span").xpath("//text()").to_s
comment.css("span").last
comment.css("span").first
comment.css("span").length
comment.css("span")
comment.children.last
comment.children.first
comment.children.length
comment.children
comment.length
comment
c
bottom.css("a").last["href"]
bottom.css("a").last
bottom.css("a").count
bottom.css("a").length
bottom.css("a").last.first.href
bottom.css("a").last.first
bottom.css("a").last
bottom.css("a").last[0]
bottom.css("a").last.count
bottom.css("a").last
bottom.css("a")
bottom
c
asdf.css("a").last
asdf = result.css("td[class=subtext]").last
      result.css("td[class=subtext]").length
      result.css("td[class=subtext]")
result
c
bottoms.count
bottoms.length
n
c
n
s
bottoms
n
response
n
url
quit
          product.mentions.find_or_create_by(comment: comment)
comment
Mention.count
product.mentions.find_or_create_by(comment_id: comment)
Mention.count
c
attrs
quit
qjuit
c
product.errors
product.save
product
n
s
product.new_record?
n
Product.count
asin
s
comment
n
asins
c
asins
quit
asins
quit
c
text.scan(URI_REGEX)
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
c
text
quit
uri.host
        uri = URI.parse(url)
uri = "http://i.imgur.com/n9TIyrk.png"
uri = http://i.imgur.com/n9TIyrk.png
    URI_REGEX = /(dp\/|gp\/product\/|gp\/offer\-listing\/)([a-zA-Z0-9]{10})/
text
asins
c
asins
c
asins
c
asins
c
asins
c
asins
c
asins
c
asins
c
asins
c
asins
c
@subsite
quit
c
data
c
listing["data"]["children"].length
listing["data"]["children"]
c
result
c
listing
listing["data"]["children"]
c
results[0]
results.length
results.class
c
listing[0]["data"]
listing.class
listing.type
JSON.load(listing)
listing["data"]
listing["data"]["children"]
listing["data"]["children"].count
listing
